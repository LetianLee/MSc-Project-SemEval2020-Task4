{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b8f750fb",
   "metadata": {},
   "source": [
    "# Experiment on Subtask A: Validation\n",
    "Updated on August 20, 2021.\n",
    "\n",
    "#### Project Information:\n",
    "* Summer Project: Commonsense Validation and Explanation in Natural Language Processing<br>\n",
    "* Objective Task: SemEval 2020 Task 4 - Commonsense Validation and Explanation (ComVE)<br>\n",
    "* Supervisor: Dr Mark Lee<br>\n",
    "* Student: Letian Li (2214560)\n",
    " \n",
    "#### Task Description:\n",
    "The subtask A is a validation task. The purpose is to determine which of two similar natural language statements is against common sense.\n",
    "\n",
    "*Example:*  \n",
    "> Task: Which of the two statements is against common sense?  \n",
    "> Statement1: He put a turkey into the fridge.  \n",
    "> Statement2: He put an elephant into the fridge. \n",
    "\n",
    "#### Solution:\n",
    "The experiment will follow the steps:\n",
    "1. General Preparation  \n",
    "2. Data Processing \n",
    "3. Loading the Model and Optimizer  \n",
    "4. Training and Evaluation \n",
    "5. Experiment "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1414590b",
   "metadata": {},
   "source": [
    "<!-- #### Task Description:\n",
    "The subtask A is a validation task. The purpose is going to tell which of two similar natural language statements is against common sense.\n",
    "\n",
    "*Example:* \n",
    "        \n",
    "    Task: Which statement of the two is against common sense?\n",
    "    Statement1: He put a turkey into the fridge.  \n",
    "    Statement2: He put an elephant into the fridge.    -->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f8a0296",
   "metadata": {},
   "source": [
    "## 1. General Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edc5fa2b",
   "metadata": {},
   "source": [
    "Import some common libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c352d68",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52a01f25",
   "metadata": {},
   "source": [
    "Use GPU Facilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e3b94deb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We are using the device cuda:3 - TITAN RTX\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "cuda_id = 3\n",
    "device = torch.device(\"cuda:%s\" % cuda_id if torch.cuda.is_available() else \"cpu\")\n",
    "device_name = torch.cuda.get_device_name(cuda_id) if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"We are using the device %s - %s\" % (device, device_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dcaacb7",
   "metadata": {},
   "source": [
    "Use TensorBoard to record and visualize the results of the experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c51f9c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter  \n",
    "\n",
    "# Set TensorBoard\n",
    "writer_tensorboard = SummaryWriter('./TensorBoard/SubtaskA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f206da46",
   "metadata": {},
   "source": [
    "## 2. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "501f58b1",
   "metadata": {},
   "source": [
    "### 2.1 Read data from csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59b2cfe3",
   "metadata": {},
   "source": [
    "Build a common function to get texts and labels from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "052592a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "def get_info_from_csv(texts_path, labels_path):\n",
    "    texts = pd.read_csv(texts_path, header=0, names=['ID', 'Statement 0', 'Statement 1'])\n",
    "    labels = pd.read_csv(labels_path, header=None, names=['ID', 'Answer'])['Answer']\n",
    "    return texts, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c03d6fe1",
   "metadata": {},
   "source": [
    "Read texts and labels from csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5b238e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_texts, train_labels = get_info_from_csv(\n",
    "    '../DataSet/Training Data/subtaskA_data_all.csv',\n",
    "    '../DataSet/Training Data/subtaskA_answers_all.csv'\n",
    ")\n",
    "\n",
    "val_texts, val_labels = get_info_from_csv(\n",
    "    '../DataSet/Dev Data/subtaskA_dev_data.csv',\n",
    "    '../DataSet/Dev Data/subtaskA_gold_answers.csv'\n",
    ")\n",
    "\n",
    "test_texts, test_labels = get_info_from_csv(\n",
    "    '../DataSet/Test Data/subtaskA_test_data.csv',\n",
    "    '../DataSet/Test Data/subtaskA_gold_answers.csv'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d8512cf",
   "metadata": {},
   "source": [
    "Let's have a look at the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10c43912",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Statement 0</th>\n",
       "      <th>Statement 1</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>He poured orange juice on his cereal.</td>\n",
       "      <td>He poured milk on his cereal.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>He drinks apple.</td>\n",
       "      <td>He drinks milk.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Jeff ran a mile today</td>\n",
       "      <td>Jeff ran 100,000 miles today</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>A mosquito stings me</td>\n",
       "      <td>I sting a mosquito</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>A niece is a person.</td>\n",
       "      <td>A giraffe is a person.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                            Statement 0                    Statement 1  \\\n",
       "0   0  He poured orange juice on his cereal.  He poured milk on his cereal.   \n",
       "1   1                       He drinks apple.                He drinks milk.   \n",
       "2   2                  Jeff ran a mile today   Jeff ran 100,000 miles today   \n",
       "3   3                   A mosquito stings me             I sting a mosquito   \n",
       "4   4                   A niece is a person.         A giraffe is a person.   \n",
       "\n",
       "   Answer  \n",
       "0       0  \n",
       "1       0  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.concat([train_texts, train_labels], axis=1)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c76df8f",
   "metadata": {},
   "source": [
    "### 2.2 Tokenization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab78b604",
   "metadata": {},
   "source": [
    "Define a function to get a tokenizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "08f1b0a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertTokenizerFast, DistilBertTokenizerFast, RobertaTokenizerFast\n",
    "\n",
    "def get_tokenizer(model_name):\n",
    "    if model_name.startswith(\"bert\"):\n",
    "        return BertTokenizerFast.from_pretrained(model_name)\n",
    "    if model_name.startswith(\"distilbert\"):\n",
    "        return DistilBertTokenizerFast.from_pretrained(model_name)\n",
    "    if model_name.startswith(\"roberta\"):\n",
    "        return RobertaTokenizerFast.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6ad387f",
   "metadata": {},
   "source": [
    "Define a function to do the tokenization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bc27675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenization(model_name):\n",
    "    # Get tokenizer\n",
    "    tokenizer = get_tokenizer(model_name)\n",
    "\n",
    "    # Tokenization for texts\n",
    "    train_encodings = tokenizer(list(train_texts[\"Statement 0\"]), list(train_texts[\"Statement 1\"]), truncation=True, padding=True)\n",
    "    val_encodings = tokenizer(list(val_texts[\"Statement 0\"]), list(val_texts[\"Statement 1\"]), truncation=True, padding=True)\n",
    "    test_encodings = tokenizer(list(test_texts[\"Statement 0\"]), list(test_texts[\"Statement 1\"]), truncation=True, padding=True)\n",
    "    \n",
    "    return train_encodings, val_encodings, test_encodings"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f794243e",
   "metadata": {},
   "source": [
    "### 2.3 Turn data into a Dataset object"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39c64e8",
   "metadata": {},
   "source": [
    "Define a Dataset class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f819e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ComVEDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, encodings, labels):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels[idx])\n",
    "        return item\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c3191",
   "metadata": {},
   "source": [
    "Define a function to get all dataset in the form of dataset objects.   \n",
    "Note that, for different models, we need to use the corresponding tokenizer to process the text data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4af9f0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(model_name):\n",
    "    # Tokenization for texts\n",
    "    train_encodings, val_encodings, test_encodings = tokenization(model_name)\n",
    "\n",
    "    # Turn encodings and labels into a Dataset object\n",
    "    train_dataset = ComVEDataset(train_encodings, train_labels)\n",
    "    val_dataset = ComVEDataset(val_encodings, val_labels)\n",
    "    test_dataset = ComVEDataset(test_encodings, test_labels)\n",
    "    \n",
    "    dataset = {\"train_dataset\" : train_dataset, \"val_dataset\" : val_dataset, \"test_dataset\" : test_dataset}\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c9b1cd3",
   "metadata": {},
   "source": [
    "## 3. Loading the Model and Optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db67215f",
   "metadata": {},
   "source": [
    "Define a function to load model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad48bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertForSequenceClassification, DistilBertForSequenceClassification, RobertaForSequenceClassification\n",
    "\n",
    "def get_model(model_name):\n",
    "    if model_name.startswith(\"bert\"):\n",
    "        model = BertForSequenceClassification.from_pretrained(model_name)\n",
    "    if model_name.startswith(\"distilbert\"):\n",
    "        model = DistilBertForSequenceClassification.from_pretrained(model_name)\n",
    "    if model_name.startswith(\"roberta\"):\n",
    "        model = RobertaForSequenceClassification.from_pretrained(model_name)\n",
    "        \n",
    "    model.to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d994d3d4",
   "metadata": {},
   "source": [
    "Define a function to load optimizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "522f3d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW\n",
    "\n",
    "def get_optimizer(model, optimizer_name, learning_rate):\n",
    "    if optimizer_name == \"Adam\":\n",
    "        return AdamW(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b6565f1",
   "metadata": {},
   "source": [
    "## 4. Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb767c4",
   "metadata": {},
   "source": [
    "Prepare some utility functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bafab666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "def predict(outputs):\n",
    "    probabilities = torch.softmax(outputs[\"logits\"], dim=1)\n",
    "    predictions = torch.argmax(probabilities, dim=1)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b8c3e4a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot function\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_and_acc(train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list, save_name=None):\n",
    "    \n",
    "    '''\n",
    "    Plot 1: Iteration vs Loss\n",
    "    '''\n",
    "    # X-axis\n",
    "    val_loss_X = (np.arange(len(val_loss_list))+1) * int(len(train_loss_list)/len(val_loss_list))  # This is to adjust the X-axis of val_loss. For each epoch, we only get one val_loss, but have len(train_dataset)/batchsize train_loss. Meanwhile, we can deduce that len(train_dataset)/batchsize = len(train_loss_list)/epoch = len(train_loss_list)/len(val_loss_list)\n",
    "\n",
    "    # plot minimum point of validation loss\n",
    "    epoch_of_min_loss = np.argmin(val_loss_list)\n",
    "    val_loss_min_point = (val_loss_X[epoch_of_min_loss], min(val_loss_list))\n",
    "    plt.axvline(x=val_loss_min_point[0],  color='gray' , linestyle='--', linewidth=0.8)\n",
    "    # plt.axhline(y=val_loss_min_point[1],  color='gray' , linestyle='--', linewidth=0.8)\n",
    "    plt.text(x=val_loss_min_point[0]*1.05, y=val_loss_min_point[1]*0.9, s=\"epoch:%s\" % (epoch_of_min_loss+1), va=\"bottom\")\n",
    "    \n",
    "    # plot curve\n",
    "    plt.plot(train_loss_list, label=\"Training Loss\")\n",
    "    plt.plot(val_loss_X, val_loss_list, label=\"Validation Loss\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Loss\")\n",
    "    plt.title(\"Iteration vs Loss\")  \n",
    "    plt.legend()\n",
    "    \n",
    "    # save the figure and display it\n",
    "    if save_name:\n",
    "        plt.savefig(save_name + \"_Loss.png\")\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    '''\n",
    "    Plot 2: Epoch vs Accuracy\n",
    "    '''\n",
    "    # X-axis\n",
    "    acc_X = np.arange(len(train_accuracy_list))+1\n",
    "    \n",
    "    # plot maximum point of validation accuracy\n",
    "    val_acc_max_point = (acc_X[np.argmax(val_accuracy_list)], max(val_accuracy_list))\n",
    "    plt.axvline(x=val_acc_max_point[0],  color='gray' , linestyle='--', linewidth=0.8)\n",
    "    plt.axhline(y=val_acc_max_point[1],  color='gray' , linestyle='--', linewidth=0.8)\n",
    "    plt.scatter(x=val_acc_max_point[0], y=val_acc_max_point[1], color=\"gray\")\n",
    "    plt.text(x=val_acc_max_point[0]*0.98, y=val_acc_max_point[1]*1.05, s=tuple([round(x,2) for x in val_acc_max_point]), ha=\"right\") \n",
    "\n",
    "    # plot curve\n",
    "    plt.plot(acc_X, train_accuracy_list,\"-\", label=\"Training Accuracy\")\n",
    "    plt.plot(acc_X, val_accuracy_list,\"-\", label=\"Validation Accuracy\")\n",
    "    plt.xlabel(\"Epoch\")\n",
    "    plt.ylabel(\"Accuracy\")\n",
    "    plt.title(\"Epoch vs Accuracy\")  \n",
    "    plt.legend()\n",
    "    \n",
    "    # save the figure and display it\n",
    "    if save_name:\n",
    "        plt.savefig(save_name + \"_Accuracy.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5c201c7",
   "metadata": {},
   "source": [
    "Prepare the evaluation function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "973f46aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation\n",
    "import numpy as np\n",
    "from torch.utils.data import DataLoader\n",
    "from pandas.core.frame import DataFrame\n",
    "\n",
    "def evaluate(model, dataset, batch_size=1, process_name=None, info=None):\n",
    "    # Get data by DataLoader\n",
    "    data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Start evaluation\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        loss_list = list()\n",
    "        record = list()\n",
    "\n",
    "        pbar = tqdm(data_loader)\n",
    "        for batch in pbar:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs['loss']\n",
    "\n",
    "            # make predictions\n",
    "            predictions = predict(outputs)\n",
    "\n",
    "            # count accuracy\n",
    "            correct += predictions.eq(labels).sum().item()\n",
    "            count += len(labels)\n",
    "            accuracy = correct * 1.0 / count\n",
    "\n",
    "            # show progress along with metrics\n",
    "            pbar.set_postfix({\n",
    "                'Loss': '{:.3f}'.format(loss.item()),\n",
    "                'Accuracy': '{:.3f}'.format(accuracy),\n",
    "                'Process': process_name if process_name else 'Evaluation'\n",
    "            })\n",
    "\n",
    "            # record the loss for each batch\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "            # use TensorBoard to record the loss and accuracy\n",
    "            if info and process_name:\n",
    "                writer_tensorboard.add_scalars(\"Loss\", {\"_\".join([process_name] + info[:-1]): loss.item()}, info[-1] )\n",
    "                writer_tensorboard.add_scalars(\"Accuracy\", {\"_\".join([process_name] + info[:-1]): accuracy}, info[-1])\n",
    "\n",
    "            # record the results\n",
    "            # record.append((int(labels),int(predictions)))\n",
    "\n",
    "        pbar.close()\n",
    "        \n",
    "    # Record the average loss and the final accuracy\n",
    "    eval_loss = np.mean(loss_list)\n",
    "    eval_accuracy = accuracy\n",
    "    \n",
    "    # Convert evaluation record to a pandas DataFrame object\n",
    "    # df_record = DataFrame(record)\n",
    "    # df_record.columns = [\"Ground Truth\",\"Model Prediction\"]\n",
    "    df_record = None\n",
    "\n",
    "    return eval_loss, eval_accuracy, df_record  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0115520",
   "metadata": {},
   "source": [
    "Prepare the training function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c26a5b6f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Training\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "def train(model, dataset, optimizer, batch_size=16, epoch=10, loss_function=None, target=None, info=None):\n",
    "\n",
    "    # Get training data by DataLoader\n",
    "    train_dataset = dataset.get(\"train_dataset\")\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    # Start training\n",
    "    model.train()\n",
    "\n",
    "    train_loss_list = list()\n",
    "    train_accuracy_list = list()\n",
    "    val_loss_list = list()\n",
    "    val_accuracy_list = list()\n",
    "    \n",
    "    iteration = 0\n",
    "    for epoch_i in range(epoch):\n",
    "        print('Epoch %s/%s' % (epoch_i + 1, epoch))\n",
    "        time.sleep(0.3)\n",
    "\n",
    "        correct = 0\n",
    "        count = 0\n",
    "        loss_list = list()\n",
    "\n",
    "        pbar = tqdm(train_loader)\n",
    "        for batch in pbar:\n",
    "            optimizer.zero_grad()\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "            outputs = model(input_ids, attention_mask=attention_mask, labels=labels)\n",
    "            loss = outputs['loss']\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # make predictions\n",
    "            predictions = predict(outputs)\n",
    "\n",
    "            # count accuracy\n",
    "            correct += predictions.eq(labels).sum().item()\n",
    "            count += len(labels)\n",
    "            accuracy = correct * 1.0 / count\n",
    "\n",
    "            # show progress along with metrics\n",
    "            pbar.set_postfix({\n",
    "                'Loss': '{:.3f}'.format(loss.item()),\n",
    "                'Accuracy': '{:.3f}'.format(accuracy),\n",
    "                'Process': 'Training'\n",
    "            })\n",
    "\n",
    "            # record the loss for each batch\n",
    "            loss_list.append(loss.item())\n",
    "            \n",
    "            # use TensorBoard to record the loss and accuracy\n",
    "            if info:\n",
    "                iteration += 1\n",
    "                writer_tensorboard.add_scalars(\"Loss\", {\"_\".join([\"Training\"] + info): loss.item()}, iteration)\n",
    "                writer_tensorboard.add_scalars(\"Accuracy\", {\"_\".join([\"Training\"] + info): accuracy}, iteration)\n",
    "\n",
    "        pbar.close()\n",
    "\n",
    "        # record the training loss and accuracy for each epoch\n",
    "        train_loss_list += loss_list\n",
    "        train_accuracy_list.append(accuracy)\n",
    "        \n",
    "        # Evaluation on validation dataset\n",
    "        val_dataset = dataset.get(\"val_dataset\")\n",
    "        val_loss, val_accuracy, __ = evaluate(model, val_dataset, batch_size=batch_size, process_name=\"Validation\", info=info+[iteration])\n",
    "        val_loss_list.append(val_loss)\n",
    "        val_accuracy_list.append(val_accuracy)\n",
    "    \n",
    "    return train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35050327",
   "metadata": {},
   "source": [
    "Training with validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "89c7a4b7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list = train(model, batch_size=128, epoch=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da92e8ca",
   "metadata": {},
   "source": [
    "Visualise the loss and accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e697dee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_loss_and_acc(train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32e12b9",
   "metadata": {},
   "source": [
    "## 5. Experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0ffdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "Experiment Different Hyperparameters with Grid Search method. \n",
    "\"\"\"\n",
    "# Select the model.\n",
    "# Check the Pretrained models on https://huggingface.co/transformers/pretrained_models.html\n",
    "# Options: [\"bert-base-uncased\" , \"distilbert-base-uncased\", \"roberta-base\", \"roberta-large\"]\n",
    "model_name = \"distilbert-base-uncased\"\n",
    "\n",
    "# Select the optimizer.\n",
    "optimizer_name = 'Adam'\n",
    "\n",
    "# Select the loss function.\n",
    "loss_name = 'CrossEntropy'\n",
    "\n",
    "# Select the learning rate list.\n",
    "# learning_rate_list = [10,1,1e-1,1e-2,1e-3,1e-4,1e-5,1e-6]       # learning rate list\n",
    "learning_rate_list = [1e-4,1e-5]                                  # learning rate list\n",
    "\n",
    "# Select the batch size list.\n",
    "# batch_size_list = [2,4,8,16,32,64,128,256]                      # batch size list\n",
    "batch_size_list = [4,8]                                           # batch size list\n",
    "\n",
    "# Select the epoch.\n",
    "epoch = 10\n",
    "    \n",
    "\n",
    "\"\"\"\n",
    "Do Experiments with Different Hyperparameters\n",
    "\"\"\"\n",
    "# Get the dataset via using the specific model tokenizer.\n",
    "dataset = get_dataset(model_name)\n",
    "\n",
    "# Create a directory for this experiment.\n",
    "task_directory = \"ExperimentResult_A\"\n",
    "experiment_name = \"_\".join([time.strftime(\"%Y%m%d_%H%M\", time.localtime()), model_name.title(), optimizer_name, loss_name])\n",
    "os.makedirs(\"./%s/%s\" % (task_directory, experiment_name))\n",
    "\n",
    "# Experiment and store the results in a CSV file.\n",
    "file_name =  \"./%s/%s/%s.csv\" % (task_directory, experiment_name, experiment_name)\n",
    "with open(file_name, 'a', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    writer.writerow([\"Model\", \"Optimizer\", \"Loss Function\", \"Learning Rate\", \"Batch Size\", \"Test Epoch\", \n",
    "                     \"Validation Loss\", \"Validation Accuracy\", \"Highest Accuracy\", \"Occurred in which Epoch\"])\n",
    "    \n",
    "    for learning_rate in learning_rate_list:\n",
    "        \n",
    "        for batch_size in batch_size_list:\n",
    "            experiment_info = [model_name.title(), optimizer_name, loss_name, \n",
    "                               \"LearningRate=%s\" % learning_rate, \"BatchSize=%s\" % batch_size, \"Epoch=%s\" % epoch]\n",
    "            print(\"Experiment:\", \" \".join(experiment_info))\n",
    "            \n",
    "            # Initialize the model\n",
    "            model = get_model(model_name)\n",
    "            \n",
    "            # Get the Optimizer\n",
    "            optimizer = get_optimizer(model, optimizer_name, learning_rate)\n",
    "            \n",
    "            # Training\n",
    "            train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list = train(\n",
    "                model = model,\n",
    "                dataset = dataset,\n",
    "                optimizer = optimizer,\n",
    "                batch_size = batch_size,\n",
    "                epoch = epoch,\n",
    "                info = experiment_info\n",
    "            )\n",
    "            \n",
    "            # Plot the result\n",
    "            save_name = \"./%s/%s/%s\" % (task_directory, experiment_name, \"_\".join(experiment_info))\n",
    "            plot_loss_and_acc(train_loss_list, train_accuracy_list, val_loss_list, val_accuracy_list, save_name)\n",
    "            \n",
    "            # Record the validation result \n",
    "            writer.writerow([model_name.title(), optimizer_name, loss_name, learning_rate, batch_size, epoch, \n",
    "                             val_loss_list, val_accuracy_list, max(val_accuracy_list), np.argmax(val_accuracy_list)+1])\n",
    "            \n",
    "            torch.cuda.empty_cache()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
